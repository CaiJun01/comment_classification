{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2490,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 1.7780438661575317,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 0.6602,
      "step": 10
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 3.8974969387054443,
      "learning_rate": 1.9847389558232933e-05,
      "loss": 0.6323,
      "step": 20
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 3.1698038578033447,
      "learning_rate": 1.9767068273092372e-05,
      "loss": 0.5722,
      "step": 30
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 2.157853364944458,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 0.4825,
      "step": 40
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 2.4115076065063477,
      "learning_rate": 1.9606425702811247e-05,
      "loss": 0.468,
      "step": 50
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 32.517330169677734,
      "learning_rate": 1.9526104417670683e-05,
      "loss": 0.4318,
      "step": 60
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 1.9675936698913574,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 0.3549,
      "step": 70
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 7.438328266143799,
      "learning_rate": 1.936546184738956e-05,
      "loss": 0.5192,
      "step": 80
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 10.53085708618164,
      "learning_rate": 1.9285140562248997e-05,
      "loss": 0.6,
      "step": 90
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 2.4312942028045654,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 0.5022,
      "step": 100
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 2.043063163757324,
      "learning_rate": 1.9124497991967875e-05,
      "loss": 0.2497,
      "step": 110
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 8.037829399108887,
      "learning_rate": 1.904417670682731e-05,
      "loss": 0.3413,
      "step": 120
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 4.860973834991455,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 0.3208,
      "step": 130
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 4.675995826721191,
      "learning_rate": 1.8883534136546186e-05,
      "loss": 0.2056,
      "step": 140
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 4.186075687408447,
      "learning_rate": 1.8803212851405622e-05,
      "loss": 0.483,
      "step": 150
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 17.491222381591797,
      "learning_rate": 1.872289156626506e-05,
      "loss": 0.2483,
      "step": 160
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 47.49208450317383,
      "learning_rate": 1.86425702811245e-05,
      "loss": 0.3856,
      "step": 170
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 8.063365936279297,
      "learning_rate": 1.856224899598394e-05,
      "loss": 0.4067,
      "step": 180
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 37.86491775512695,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 0.3346,
      "step": 190
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 38.680328369140625,
      "learning_rate": 1.8401606425702815e-05,
      "loss": 0.2876,
      "step": 200
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 51.264286041259766,
      "learning_rate": 1.832128514056225e-05,
      "loss": 0.3599,
      "step": 210
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 55.041255950927734,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 0.3664,
      "step": 220
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 17.17788314819336,
      "learning_rate": 1.8160642570281125e-05,
      "loss": 0.2133,
      "step": 230
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 7.9206767082214355,
      "learning_rate": 1.8080321285140565e-05,
      "loss": 0.3767,
      "step": 240
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 10.211906433105469,
      "learning_rate": 1.8e-05,
      "loss": 0.3672,
      "step": 250
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 0.2525143325328827,
      "learning_rate": 1.791967871485944e-05,
      "loss": 0.1234,
      "step": 260
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 8.696426391601562,
      "learning_rate": 1.783935742971888e-05,
      "loss": 0.4631,
      "step": 270
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 0.3983232378959656,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 0.2813,
      "step": 280
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 29.339588165283203,
      "learning_rate": 1.7678714859437754e-05,
      "loss": 0.1673,
      "step": 290
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 41.00558853149414,
      "learning_rate": 1.759839357429719e-05,
      "loss": 0.3642,
      "step": 300
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 13.035317420959473,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 0.4396,
      "step": 310
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 2.0181891918182373,
      "learning_rate": 1.7437751004016065e-05,
      "loss": 0.2945,
      "step": 320
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 0.7517428994178772,
      "learning_rate": 1.7357429718875504e-05,
      "loss": 0.1908,
      "step": 330
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 41.3464469909668,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 0.3053,
      "step": 340
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 0.20502254366874695,
      "learning_rate": 1.719678714859438e-05,
      "loss": 0.3272,
      "step": 350
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 6.158514976501465,
      "learning_rate": 1.7116465863453818e-05,
      "loss": 0.5706,
      "step": 360
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 13.043416976928711,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 0.4378,
      "step": 370
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 3.277137517929077,
      "learning_rate": 1.6955823293172693e-05,
      "loss": 0.4329,
      "step": 380
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.45125263929367065,
      "learning_rate": 1.687550200803213e-05,
      "loss": 0.2019,
      "step": 390
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 3.1814866065979004,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 0.5185,
      "step": 400
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 1.1385002136230469,
      "learning_rate": 1.6714859437751004e-05,
      "loss": 0.3419,
      "step": 410
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 23.62380599975586,
      "learning_rate": 1.6634538152610443e-05,
      "loss": 0.4043,
      "step": 420
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 7.233989715576172,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 0.2145,
      "step": 430
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 13.179821014404297,
      "learning_rate": 1.6473895582329318e-05,
      "loss": 0.1871,
      "step": 440
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 0.8695816993713379,
      "learning_rate": 1.6393574297188757e-05,
      "loss": 0.2045,
      "step": 450
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 4.691147327423096,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 0.3332,
      "step": 460
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 12.352853775024414,
      "learning_rate": 1.6232931726907632e-05,
      "loss": 0.4593,
      "step": 470
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 10.307121276855469,
      "learning_rate": 1.6152610441767068e-05,
      "loss": 0.2547,
      "step": 480
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 0.2549741864204407,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 0.121,
      "step": 490
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 4.609922885894775,
      "learning_rate": 1.5991967871485947e-05,
      "loss": 0.4602,
      "step": 500
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 4.286522388458252,
      "learning_rate": 1.5911646586345382e-05,
      "loss": 0.339,
      "step": 510
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 13.421671867370605,
      "learning_rate": 1.583132530120482e-05,
      "loss": 0.1635,
      "step": 520
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 5.072319984436035,
      "learning_rate": 1.5751004016064257e-05,
      "loss": 0.3603,
      "step": 530
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 5.770135879516602,
      "learning_rate": 1.5670682730923697e-05,
      "loss": 0.4299,
      "step": 540
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 6.589806079864502,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 0.2215,
      "step": 550
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 11.029052734375,
      "learning_rate": 1.551004016064257e-05,
      "loss": 0.5123,
      "step": 560
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 12.575931549072266,
      "learning_rate": 1.5429718875502007e-05,
      "loss": 0.3512,
      "step": 570
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 22.520418167114258,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 0.3074,
      "step": 580
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 4.896922588348389,
      "learning_rate": 1.5269076305220886e-05,
      "loss": 0.2671,
      "step": 590
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 36.28412628173828,
      "learning_rate": 1.5188755020080323e-05,
      "loss": 0.1594,
      "step": 600
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 6.436474323272705,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 0.1968,
      "step": 610
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 5.9307146072387695,
      "learning_rate": 1.5028112449799197e-05,
      "loss": 0.3204,
      "step": 620
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 15.089700698852539,
      "learning_rate": 1.4947791164658636e-05,
      "loss": 0.3077,
      "step": 630
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 5.4022369384765625,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 0.2547,
      "step": 640
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 0.9159806966781616,
      "learning_rate": 1.4787148594377511e-05,
      "loss": 0.2563,
      "step": 650
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 6.364682197570801,
      "learning_rate": 1.4706827309236948e-05,
      "loss": 0.2378,
      "step": 660
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 4.464170455932617,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 0.3213,
      "step": 670
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 0.24373649060726166,
      "learning_rate": 1.4546184738955823e-05,
      "loss": 0.2223,
      "step": 680
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 10.013299942016602,
      "learning_rate": 1.4465863453815263e-05,
      "loss": 0.3147,
      "step": 690
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 13.929049491882324,
      "learning_rate": 1.43855421686747e-05,
      "loss": 0.1192,
      "step": 700
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 0.27824100852012634,
      "learning_rate": 1.4305220883534136e-05,
      "loss": 0.3936,
      "step": 710
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 1.0121523141860962,
      "learning_rate": 1.4224899598393575e-05,
      "loss": 0.2563,
      "step": 720
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 19.212188720703125,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 0.3964,
      "step": 730
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 20.461519241333008,
      "learning_rate": 1.4064257028112452e-05,
      "loss": 0.2793,
      "step": 740
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 6.574068546295166,
      "learning_rate": 1.3983935742971888e-05,
      "loss": 0.3463,
      "step": 750
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 22.25934410095215,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 0.2022,
      "step": 760
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 4.440781116485596,
      "learning_rate": 1.3823293172690764e-05,
      "loss": 0.2763,
      "step": 770
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 7.360549449920654,
      "learning_rate": 1.3742971887550204e-05,
      "loss": 0.5566,
      "step": 780
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 13.755398750305176,
      "learning_rate": 1.366265060240964e-05,
      "loss": 0.1898,
      "step": 790
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.5890901684761047,
      "learning_rate": 1.3582329317269079e-05,
      "loss": 0.4186,
      "step": 800
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 12.09515380859375,
      "learning_rate": 1.3502008032128514e-05,
      "loss": 0.2805,
      "step": 810
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 3.2811038494110107,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 0.1771,
      "step": 820
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3418465852737427,
      "learning_rate": 1.3341365461847391e-05,
      "loss": 0.1127,
      "step": 830
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 58.676300048828125,
      "learning_rate": 1.3261044176706827e-05,
      "loss": 0.0869,
      "step": 840
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.34834808111190796,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 0.1189,
      "step": 850
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 22.0856876373291,
      "learning_rate": 1.3100401606425704e-05,
      "loss": 0.1844,
      "step": 860
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 0.09186616539955139,
      "learning_rate": 1.3020080321285143e-05,
      "loss": 0.1575,
      "step": 870
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 0.08423754572868347,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 0.2722,
      "step": 880
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 0.08375950157642365,
      "learning_rate": 1.2859437751004018e-05,
      "loss": 0.0659,
      "step": 890
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 0.06622456014156342,
      "learning_rate": 1.2779116465863455e-05,
      "loss": 0.2215,
      "step": 900
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 0.09622681885957718,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 0.2156,
      "step": 910
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 0.3478451669216156,
      "learning_rate": 1.261847389558233e-05,
      "loss": 0.1029,
      "step": 920
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 0.04959676042199135,
      "learning_rate": 1.2538152610441768e-05,
      "loss": 0.0654,
      "step": 930
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 0.04301316663622856,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 0.0406,
      "step": 940
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 27.531522750854492,
      "learning_rate": 1.2377510040160643e-05,
      "loss": 0.0491,
      "step": 950
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.0801205188035965,
      "learning_rate": 1.2297188755020082e-05,
      "loss": 0.5793,
      "step": 960
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 11.887520790100098,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 0.3018,
      "step": 970
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 13.917571067810059,
      "learning_rate": 1.2136546184738957e-05,
      "loss": 0.5847,
      "step": 980
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.23948173224925995,
      "learning_rate": 1.2056224899598395e-05,
      "loss": 0.0797,
      "step": 990
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 4.912149429321289,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 0.2461,
      "step": 1000
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 0.24420814216136932,
      "learning_rate": 1.189558232931727e-05,
      "loss": 0.1639,
      "step": 1010
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 0.13637790083885193,
      "learning_rate": 1.1815261044176707e-05,
      "loss": 0.1423,
      "step": 1020
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.2169933170080185,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 0.0655,
      "step": 1030
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 22.18787956237793,
      "learning_rate": 1.1654618473895582e-05,
      "loss": 0.263,
      "step": 1040
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 5.452763557434082,
      "learning_rate": 1.1574297188755021e-05,
      "loss": 0.2413,
      "step": 1050
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.12602446973323822,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 0.3035,
      "step": 1060
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 15.306056022644043,
      "learning_rate": 1.1413654618473898e-05,
      "loss": 0.3542,
      "step": 1070
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 0.6899653673171997,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0851,
      "step": 1080
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.49553626775741577,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 0.1993,
      "step": 1090
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 5.268970489501953,
      "learning_rate": 1.117269076305221e-05,
      "loss": 0.2534,
      "step": 1100
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.2408444583415985,
      "learning_rate": 1.1092369477911646e-05,
      "loss": 0.0577,
      "step": 1110
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 0.2009858936071396,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 0.2301,
      "step": 1120
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 7.500390529632568,
      "learning_rate": 1.0931726907630521e-05,
      "loss": 0.1402,
      "step": 1130
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 0.07327170670032501,
      "learning_rate": 1.085140562248996e-05,
      "loss": 0.2671,
      "step": 1140
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 20.75900650024414,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 0.1994,
      "step": 1150
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 25.8643741607666,
      "learning_rate": 1.0690763052208837e-05,
      "loss": 0.1501,
      "step": 1160
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 23.93350601196289,
      "learning_rate": 1.0610441767068273e-05,
      "loss": 0.1868,
      "step": 1170
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 2.3670809268951416,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 0.2791,
      "step": 1180
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 5.408156394958496,
      "learning_rate": 1.044979919678715e-05,
      "loss": 0.2272,
      "step": 1190
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 5.822803020477295,
      "learning_rate": 1.0369477911646589e-05,
      "loss": 0.0912,
      "step": 1200
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 0.874830961227417,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 0.1565,
      "step": 1210
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 0.501302182674408,
      "learning_rate": 1.0208835341365462e-05,
      "loss": 0.2503,
      "step": 1220
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 0.1141691505908966,
      "learning_rate": 1.0128514056224901e-05,
      "loss": 0.2265,
      "step": 1230
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 0.13721734285354614,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 0.0359,
      "step": 1240
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 0.13769815862178802,
      "learning_rate": 9.967871485943776e-06,
      "loss": 0.1849,
      "step": 1250
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 0.056897539645433426,
      "learning_rate": 9.887550200803212e-06,
      "loss": 0.1099,
      "step": 1260
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 5.702152252197266,
      "learning_rate": 9.807228915662652e-06,
      "loss": 0.106,
      "step": 1270
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 0.6073775887489319,
      "learning_rate": 9.726907630522089e-06,
      "loss": 0.1436,
      "step": 1280
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 0.08706388622522354,
      "learning_rate": 9.646586345381527e-06,
      "loss": 0.1072,
      "step": 1290
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 0.116395965218544,
      "learning_rate": 9.566265060240964e-06,
      "loss": 0.5401,
      "step": 1300
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 40.24138641357422,
      "learning_rate": 9.485943775100403e-06,
      "loss": 0.1877,
      "step": 1310
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 0.342469722032547,
      "learning_rate": 9.40562248995984e-06,
      "loss": 0.1079,
      "step": 1320
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 8.486316680908203,
      "learning_rate": 9.325301204819278e-06,
      "loss": 0.3433,
      "step": 1330
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.35080909729003906,
      "learning_rate": 9.244979919678716e-06,
      "loss": 0.1572,
      "step": 1340
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 0.10548266768455505,
      "learning_rate": 9.164658634538153e-06,
      "loss": 0.1088,
      "step": 1350
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 0.09228238463401794,
      "learning_rate": 9.08433734939759e-06,
      "loss": 0.1714,
      "step": 1360
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 5.813846111297607,
      "learning_rate": 9.004016064257028e-06,
      "loss": 0.1806,
      "step": 1370
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.07794135808944702,
      "learning_rate": 8.923694779116466e-06,
      "loss": 0.194,
      "step": 1380
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 13.392800331115723,
      "learning_rate": 8.843373493975905e-06,
      "loss": 0.2371,
      "step": 1390
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.10850309580564499,
      "learning_rate": 8.763052208835342e-06,
      "loss": 0.1858,
      "step": 1400
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 15.73803997039795,
      "learning_rate": 8.68273092369478e-06,
      "loss": 0.27,
      "step": 1410
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 11.139671325683594,
      "learning_rate": 8.602409638554217e-06,
      "loss": 0.2361,
      "step": 1420
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 47.71961975097656,
      "learning_rate": 8.522088353413655e-06,
      "loss": 0.0961,
      "step": 1430
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 0.11894451826810837,
      "learning_rate": 8.441767068273094e-06,
      "loss": 0.0678,
      "step": 1440
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 18.2684268951416,
      "learning_rate": 8.361445783132532e-06,
      "loss": 0.2103,
      "step": 1450
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 0.09425047785043716,
      "learning_rate": 8.281124497991968e-06,
      "loss": 0.187,
      "step": 1460
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 13.79998779296875,
      "learning_rate": 8.200803212851407e-06,
      "loss": 0.0815,
      "step": 1470
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 29.90074920654297,
      "learning_rate": 8.120481927710844e-06,
      "loss": 0.1195,
      "step": 1480
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 48.40824890136719,
      "learning_rate": 8.040160642570282e-06,
      "loss": 0.3788,
      "step": 1490
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 41.4617919921875,
      "learning_rate": 7.95983935742972e-06,
      "loss": 0.3239,
      "step": 1500
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.11410941928625107,
      "learning_rate": 7.879518072289157e-06,
      "loss": 0.1999,
      "step": 1510
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 9.802290916442871,
      "learning_rate": 7.799196787148596e-06,
      "loss": 0.2396,
      "step": 1520
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 10.20162296295166,
      "learning_rate": 7.718875502008033e-06,
      "loss": 0.2817,
      "step": 1530
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 0.14996792376041412,
      "learning_rate": 7.638554216867471e-06,
      "loss": 0.2603,
      "step": 1540
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 37.79176712036133,
      "learning_rate": 7.5582329317269085e-06,
      "loss": 0.1205,
      "step": 1550
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.20061668753623962,
      "learning_rate": 7.477911646586345e-06,
      "loss": 0.1014,
      "step": 1560
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 0.8598076105117798,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 0.0669,
      "step": 1570
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 0.749277651309967,
      "learning_rate": 7.317269076305221e-06,
      "loss": 0.2858,
      "step": 1580
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 0.1950664520263672,
      "learning_rate": 7.236947791164659e-06,
      "loss": 0.1924,
      "step": 1590
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 14.477526664733887,
      "learning_rate": 7.156626506024097e-06,
      "loss": 0.3168,
      "step": 1600
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 0.1868225783109665,
      "learning_rate": 7.076305220883535e-06,
      "loss": 0.0955,
      "step": 1610
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 8.116817474365234,
      "learning_rate": 6.995983935742973e-06,
      "loss": 0.1759,
      "step": 1620
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 28.885448455810547,
      "learning_rate": 6.91566265060241e-06,
      "loss": 0.2309,
      "step": 1630
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 0.1541498899459839,
      "learning_rate": 6.8353413654618486e-06,
      "loss": 0.1728,
      "step": 1640
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 2.0752832889556885,
      "learning_rate": 6.755020080321286e-06,
      "loss": 0.0091,
      "step": 1650
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0706348717212677,
      "learning_rate": 6.674698795180723e-06,
      "loss": 0.2852,
      "step": 1660
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 30.375295639038086,
      "learning_rate": 6.594377510040161e-06,
      "loss": 0.1261,
      "step": 1670
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 13.167913436889648,
      "learning_rate": 6.514056224899599e-06,
      "loss": 0.0658,
      "step": 1680
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.0981023982167244,
      "learning_rate": 6.433734939759036e-06,
      "loss": 0.0734,
      "step": 1690
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 0.04230720177292824,
      "learning_rate": 6.3534136546184744e-06,
      "loss": 0.0379,
      "step": 1700
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.1330045759677887,
      "learning_rate": 6.273092369477912e-06,
      "loss": 0.0877,
      "step": 1710
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.06916404515504837,
      "learning_rate": 6.19277108433735e-06,
      "loss": 0.0754,
      "step": 1720
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 0.4920324385166168,
      "learning_rate": 6.112449799196788e-06,
      "loss": 0.0032,
      "step": 1730
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.16414010524749756,
      "learning_rate": 6.032128514056226e-06,
      "loss": 0.0182,
      "step": 1740
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 14.67822551727295,
      "learning_rate": 5.951807228915664e-06,
      "loss": 0.2,
      "step": 1750
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 0.05411764234304428,
      "learning_rate": 5.8714859437751e-06,
      "loss": 0.0807,
      "step": 1760
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 0.06286866217851639,
      "learning_rate": 5.791164658634538e-06,
      "loss": 0.0961,
      "step": 1770
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 12.361862182617188,
      "learning_rate": 5.710843373493976e-06,
      "loss": 0.2916,
      "step": 1780
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 0.14169913530349731,
      "learning_rate": 5.630522088353414e-06,
      "loss": 0.0631,
      "step": 1790
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.09779606759548187,
      "learning_rate": 5.550200803212852e-06,
      "loss": 0.0397,
      "step": 1800
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.032928839325904846,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 0.1065,
      "step": 1810
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.06200890615582466,
      "learning_rate": 5.389558232931728e-06,
      "loss": 0.0045,
      "step": 1820
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 1.026059865951538,
      "learning_rate": 5.309236947791165e-06,
      "loss": 0.0392,
      "step": 1830
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 0.0742475688457489,
      "learning_rate": 5.228915662650603e-06,
      "loss": 0.2107,
      "step": 1840
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.07134000211954117,
      "learning_rate": 5.148594377510041e-06,
      "loss": 0.0915,
      "step": 1850
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 24.40265655517578,
      "learning_rate": 5.068273092369478e-06,
      "loss": 0.2438,
      "step": 1860
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 54.26521301269531,
      "learning_rate": 4.987951807228916e-06,
      "loss": 0.1714,
      "step": 1870
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.19664819538593292,
      "learning_rate": 4.907630522088354e-06,
      "loss": 0.2401,
      "step": 1880
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.11306214332580566,
      "learning_rate": 4.827309236947791e-06,
      "loss": 0.2138,
      "step": 1890
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 5.787951469421387,
      "learning_rate": 4.74698795180723e-06,
      "loss": 0.1519,
      "step": 1900
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 13.210494041442871,
      "learning_rate": 4.666666666666667e-06,
      "loss": 0.0643,
      "step": 1910
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 13.042259216308594,
      "learning_rate": 4.586345381526105e-06,
      "loss": 0.0901,
      "step": 1920
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 0.04950796067714691,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.1277,
      "step": 1930
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.5790224671363831,
      "learning_rate": 4.4257028112449805e-06,
      "loss": 0.1228,
      "step": 1940
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 0.5477674007415771,
      "learning_rate": 4.345381526104418e-06,
      "loss": 0.1598,
      "step": 1950
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 0.09552226960659027,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.1711,
      "step": 1960
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 0.31460028886795044,
      "learning_rate": 4.184738955823294e-06,
      "loss": 0.0066,
      "step": 1970
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.04171335697174072,
      "learning_rate": 4.104417670682731e-06,
      "loss": 0.1024,
      "step": 1980
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 0.058922309428453445,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.1739,
      "step": 1990
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 2.3201510906219482,
      "learning_rate": 3.943775100401606e-06,
      "loss": 0.0406,
      "step": 2000
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.1347443014383316,
      "learning_rate": 3.863453815261045e-06,
      "loss": 0.0021,
      "step": 2010
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 5.762583255767822,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.1553,
      "step": 2020
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 0.07991968095302582,
      "learning_rate": 3.7028112449799198e-06,
      "loss": 0.0023,
      "step": 2030
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 0.34204041957855225,
      "learning_rate": 3.6224899598393577e-06,
      "loss": 0.0783,
      "step": 2040
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.031168943271040916,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.1015,
      "step": 2050
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 0.892859935760498,
      "learning_rate": 3.461847389558233e-06,
      "loss": 0.0073,
      "step": 2060
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 0.04156592860817909,
      "learning_rate": 3.381526104417671e-06,
      "loss": 0.0982,
      "step": 2070
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 0.04084928706288338,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.0311,
      "step": 2080
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 0.03654799237847328,
      "learning_rate": 3.2208835341365465e-06,
      "loss": 0.1125,
      "step": 2090
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 0.15143604576587677,
      "learning_rate": 3.140562248995984e-06,
      "loss": 0.0016,
      "step": 2100
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 0.5836029052734375,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.1354,
      "step": 2110
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.13176383078098297,
      "learning_rate": 2.97991967871486e-06,
      "loss": 0.0365,
      "step": 2120
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 0.029327983036637306,
      "learning_rate": 2.8995983935742974e-06,
      "loss": 0.0879,
      "step": 2130
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 0.04589055851101875,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.0799,
      "step": 2140
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 0.08359305560588837,
      "learning_rate": 2.738955823293173e-06,
      "loss": 0.0842,
      "step": 2150
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 12.080207824707031,
      "learning_rate": 2.6586345381526107e-06,
      "loss": 0.2996,
      "step": 2160
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 0.06788979470729828,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.0397,
      "step": 2170
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 0.047502849251031876,
      "learning_rate": 2.497991967871486e-06,
      "loss": 0.0523,
      "step": 2180
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 7.332102298736572,
      "learning_rate": 2.4176706827309237e-06,
      "loss": 0.1578,
      "step": 2190
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 0.0708792582154274,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.1454,
      "step": 2200
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 39.71351623535156,
      "learning_rate": 2.2570281124497996e-06,
      "loss": 0.1183,
      "step": 2210
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 2.949942111968994,
      "learning_rate": 2.176706827309237e-06,
      "loss": 0.0033,
      "step": 2220
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 0.06199932470917702,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.1171,
      "step": 2230
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 0.0643567442893982,
      "learning_rate": 2.0160642570281125e-06,
      "loss": 0.0902,
      "step": 2240
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 0.1350327730178833,
      "learning_rate": 1.9357429718875504e-06,
      "loss": 0.0479,
      "step": 2250
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 6.347351551055908,
      "learning_rate": 1.8554216867469881e-06,
      "loss": 0.1639,
      "step": 2260
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 0.15281273424625397,
      "learning_rate": 1.7751004016064259e-06,
      "loss": 0.1836,
      "step": 2270
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 0.037648722529411316,
      "learning_rate": 1.6947791164658636e-06,
      "loss": 0.0044,
      "step": 2280
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 6.9964799880981445,
      "learning_rate": 1.6144578313253013e-06,
      "loss": 0.1163,
      "step": 2290
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 1.6951090097427368,
      "learning_rate": 1.534136546184739e-06,
      "loss": 0.0675,
      "step": 2300
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 0.3525817096233368,
      "learning_rate": 1.453815261044177e-06,
      "loss": 0.1348,
      "step": 2310
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 0.029882887378335,
      "learning_rate": 1.3734939759036144e-06,
      "loss": 0.1447,
      "step": 2320
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 0.15981978178024292,
      "learning_rate": 1.2931726907630524e-06,
      "loss": 0.0698,
      "step": 2330
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 0.03348260745406151,
      "learning_rate": 1.21285140562249e-06,
      "loss": 0.1291,
      "step": 2340
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 0.040589358657598495,
      "learning_rate": 1.1325301204819278e-06,
      "loss": 0.0165,
      "step": 2350
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.03418442979454994,
      "learning_rate": 1.0522088353413655e-06,
      "loss": 0.1279,
      "step": 2360
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.19018255174160004,
      "learning_rate": 9.718875502008035e-07,
      "loss": 0.0081,
      "step": 2370
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 0.032149434089660645,
      "learning_rate": 8.915662650602411e-07,
      "loss": 0.0205,
      "step": 2380
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 1.9540801048278809,
      "learning_rate": 8.112449799196788e-07,
      "loss": 0.0039,
      "step": 2390
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.027467451989650726,
      "learning_rate": 7.309236947791165e-07,
      "loss": 0.0171,
      "step": 2400
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.05453338101506233,
      "learning_rate": 6.506024096385542e-07,
      "loss": 0.0779,
      "step": 2410
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 1.021572470664978,
      "learning_rate": 5.702811244979921e-07,
      "loss": 0.0756,
      "step": 2420
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 0.15604273974895477,
      "learning_rate": 4.899598393574298e-07,
      "loss": 0.1713,
      "step": 2430
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 0.0519968681037426,
      "learning_rate": 4.0963855421686754e-07,
      "loss": 0.077,
      "step": 2440
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 0.12063617259263992,
      "learning_rate": 3.2931726907630526e-07,
      "loss": 0.0016,
      "step": 2450
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 0.15643265843391418,
      "learning_rate": 2.48995983935743e-07,
      "loss": 0.0861,
      "step": 2460
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.05028644576668739,
      "learning_rate": 1.6867469879518075e-07,
      "loss": 0.085,
      "step": 2470
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 0.04211569204926491,
      "learning_rate": 8.835341365461847e-08,
      "loss": 0.0999,
      "step": 2480
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.026758940890431404,
      "learning_rate": 8.032128514056226e-09,
      "loss": 0.0567,
      "step": 2490
    }
  ],
  "logging_steps": 10,
  "max_steps": 2490,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1308935196467712.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
